{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "700d57bd-ea7b-47be-8ce0-e53fb3502529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f440a628-c681-4782-b381-b7956efe6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorios de entrenamiento y prueba\n",
    "train_dir = 'C:/Users/Usuario/Desktop/chest_xray/train'\n",
    "test_dir = 'C:/Users/Usuario/Desktop/chest_xray/test'\n",
    "val_dir = 'C:/Users/Usuario/Desktop/chest_xray/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0407389f-02f4-402b-937c-8735fad3d586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Configurar generadores de imágenes\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ba896a-7e9b-461f-b0e4-3b101746a1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 150, 150, 32)      320       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 150, 150, 32)      128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 75, 75, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 75, 75, 64)        18496     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 75, 75, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 38, 38, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 38, 38, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 38, 38, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 19, 19, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 19, 19, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 19, 19, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 10, 10, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 10, 10, 256)       295168    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 10, 10, 256)       0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 10, 10, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 5, 5, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               819328    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1246401 (4.75 MB)\n",
      "Trainable params: 1245313 (4.75 MB)\n",
      "Non-trainable params: 1088 (4.25 KB)\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: modelo_neumonia.final\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelo_neumonia.final\\assets\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (150,150,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128 , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 1 , activation = 'sigmoid'))\n",
    "model.compile(optimizer = RMSprop() , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()\n",
    "model.save('modelo_neumonia.final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aafd3998-ece8-4612-b7f9-42c7925760e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "WARNING:tensorflow:From C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 170s 988ms/step - loss: 0.4660 - accuracy: 0.8786 - val_loss: 50.4661 - val_accuracy: 0.5000\n",
      "Epoch 2/7\n",
      "163/163 [==============================] - 126s 774ms/step - loss: 0.1340 - accuracy: 0.9607 - val_loss: 72.3236 - val_accuracy: 0.5000\n",
      "Epoch 3/7\n",
      "163/163 [==============================] - 121s 740ms/step - loss: 0.1053 - accuracy: 0.9680 - val_loss: 16.3757 - val_accuracy: 0.5000\n",
      "Epoch 4/7\n",
      "163/163 [==============================] - 123s 753ms/step - loss: 0.0600 - accuracy: 0.9780 - val_loss: 6.0113 - val_accuracy: 0.5000\n",
      "Epoch 5/7\n",
      "163/163 [==============================] - 126s 772ms/step - loss: 0.0647 - accuracy: 0.9783 - val_loss: 31.5294 - val_accuracy: 0.5000\n",
      "Epoch 6/7\n",
      "163/163 [==============================] - 124s 762ms/step - loss: 0.0468 - accuracy: 0.9858 - val_loss: 0.9511 - val_accuracy: 0.8750\n",
      "Epoch 7/7\n",
      "163/163 [==============================] - 127s 780ms/step - loss: 0.0474 - accuracy: 0.9852 - val_loss: 0.2375 - val_accuracy: 0.8125\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=7,\n",
    "    validation_data=val_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c93af5-e52c-4989-8ff7-e7274b759935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 8s 347ms/step\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 2.3778 - accuracy: 0.7115\n",
      "Test Accuracy: 0.7115384340286255\n"
     ]
    }
   ],
   "source": [
    "# Hacer predicciones en datos de prueba\n",
    "predictions = model.predict(test_generator)\n",
    "\n",
    "# Evaluar el modelo en datos de prueba\n",
    "evaluation = model.evaluate(test_generator)\n",
    "\n",
    "# Por ejemplo, imprimir la precisión en datos de prueba\n",
    "print(\"Test Accuracy:\", evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beb96c61-948d-4f87-8513-72c29867601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Valor de predicción: 0.5009791\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Valor de predicción: 0.49975148\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Valor de predicción: 0.49984214\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Valor de predicción: 0.49984214\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Valor de predicción: 0.50096875\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Valor de predicción: 0.5015393\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Valor de predicción: 0.50094056\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Valor de predicción: 0.49984214\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Valor de predicción: 0.49965838\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Valor de predicción: 0.5000484\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Valor de predicción: 0.49984214\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Valor de predicción: 0.50142556\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Valor de predicción: 0.49984214\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Valor de predicción: 0.50199455\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Valor de predicción: 0.50151134\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Valor de predicción: 0.49984214\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "Valor de predicción: 0.5015675\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "Valor de predicción: 0.501322\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "Valor de predicción: 0.5015875\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "Valor de predicción: 0.50087875\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 1s 560ms/step\n",
      "Valor de predicción: 0.49982107\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "Valor de predicción: 0.49901366\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "model = tf.keras.models.load_model('modelo_neumonia.final')\n",
    "\n",
    "# Función para realizar predicciones\n",
    "def predict_image(img):\n",
    "    # Manejar el caso de una sola imagen (sin lote)\n",
    "    if len(img.shape) == 2:  \n",
    "        img = np.expand_dims(img, axis=0)\n",
    "    elif len(img.shape) == 3 and img.shape[-1] == 1:\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "\n",
    "    # Convertir la imagen a escala de grises\n",
    "    img = image.array_to_img(img, data_format='channels_last')\n",
    "    img = img.convert('L')  # Convertir a escala de grises\n",
    "    img = img.resize((150, 150))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = img / 255.0  # Normalizar la imagen\n",
    "\n",
    "    # Realizar la predicción\n",
    "    prediction = model.predict(img)\n",
    "    # Realizar la predicción\n",
    "    prediction = model.predict(img)\n",
    "    print(\"Valor de predicción:\", prediction[0][0])\n",
    "\n",
    "    # Devolver la predicción (1: neumonía, 0: normal)\n",
    "    return 'Neumonía' if prediction[0][0] > 0.5 else 'Normal'\n",
    "\n",
    "\n",
    "    # Devolver la predicción (1: neumonía, 0: normal)\n",
    "    return 'Neumonía' if prediction[0][0] > 0.5 else 'Normal'\n",
    "\n",
    "# Crear una interfaz de Gradio\n",
    "iface = gr.Interface(\n",
    "    fn=predict_image,\n",
    "    inputs=\"image\",\n",
    "    outputs=\"text\",\n",
    "    live=True\n",
    ")\n",
    "\n",
    "# Ejecutar la interfaz\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe460278-9560-4f33-bf0e-a5e79ee989e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = [i for i in range(7)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "fig.set_size_inches(20,10)\n",
    "\n",
    "ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n",
    "ax[0].plot(epochs , val_acc , 'ro-' , label = 'Validation Accuracy')\n",
    "ax[0].set_title('Training & Validation Accuracy')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\n",
    "ax[1].plot(epochs , val_loss , 'r-o' , label = 'Validation Loss')\n",
    "ax[1].set_title('Testing Accuracy & Loss')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"Training & Validation Loss\")\n",
    "plt.show()\n",
    "# Código para guardar la imagen\n",
    "fig.savefig('training_plot.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
